## Fuzz Testing based Data Augmentation to Improve Robustness of Deep Neural Networks

**使用基于模糊测试的数据增强方法来提高$\mathbf{DNN}$的鲁棒性，与生成新的测试输入(对抗样本)之后重训练模型不同，此方法在训练过程的每次迭代时进行数据增强以提升模型鲁棒性**

#### 背景

基于测试的程序合成与自动修复方法会自动生成满足指定样本条件的程序，但是由于给定样本不能完美描述预期行为，会导致生成程序的过拟合问题。过拟合通常导致模型泛化能力不强(仅在训练集上有较高预测准确率)和鲁棒性较差(预测准确性较高，但是对微小扰动敏感)的问题。

鲁棒性生成可分为两类：**针对对抗样本的鲁棒性生成**和**获取数据时自然环境改变而产生扰动**(例如自动驾驶汽车同一地点天气变化)

* 模糊测试：一种通过对输入进行变异，生成新的测试输入来检测软件错误的方法。通过选择变异的种子并控制生成的变异体数量来实现指定测试目标。
* $DNN$的鲁棒性：对抗数据扰动的能力
* $DNN$的数据增强：$DNN$训练过程中可能对训练数据中一些不相关特征进行学习(过拟合)，导致对其他数据的泛化能力降低。而数据增强就是在训练过程中对训练数据添加扰动，以增强模型的泛化能力。数据增强可以在**初始训练**(使用启发式方法即时生成合成数据扩充数据集)或**再训练**(在第一次训练时根据反馈选择数据，并在再训练时扩充数据)时进行

#### 主要贡献

* 将“用于$DNN$鲁棒性泛化的数据增强问题”形式化为搜索问题，并用基于模糊测试的遗传搜索算法来解决
* 提出一种选择性的数据扩充策略来减少数据扩充的开销，仅选择部分数据点进行扩充
* 实现了$SENSEI$和$SENSEI$-$SA$两个原型工具实现提出的方法
* 使用15个$DNN$模型和5个图片数据集进行评估，结果显示$SENSEI$与最新方法相比最高能提升$11.9\%$的鲁棒准确性(平均$5.5\%$)，$SENSEI$-$SA$能减少$25\%$的训练时间并提高鲁棒准确性(目前仅对图像分类进行了评估，理论上有更广泛的适用性)

#### 方法介绍

$\mathbf{SENSEI}$是一个$DNN$的自动化数据增强框架，目的是在自然环境产生的变体下，增强$DNN$的鲁棒性泛化能力。通过对部分数据进行替换来增添强数据(不改变数据集大小)，因此$SENSEI$的最大贡献就是如何选择最佳的替换数据。然后又提供了$SENSEI$-$SA$算法，通过跳过某些数据点的增强来减少训练时间。

**优化思路**：在泛化鲁棒性的要求下训练$DNN$的问题可以被转化为凸优化$(saddle\ point\ optimization)$问题：除了优化权重参数$\theta$之外还要为每个训练输入$x$找到最佳变体$x'=x+\delta$，因此有目标函数$\underset{\theta}{min}E_{(x,y)\sim D}[\underset{\delta\in S}{max}L(\theta,x+\delta,y)]$，通过将内部的最大化问题与外部的最小化问题解耦，来估计最优值。根据种子训练输入$x$，和$x$的邻域$S$的转换函数$t(\overset{\rightarrow}{\rho},x)$，找到能生成最佳变体$x'$的$\overset{\rightarrow}{\rho}$：$\underset{\overset{\rightarrow}{\rho}\in S}{max}L(\theta,t(\overset{\rightarrow}{\rho},x),y)$

**算法思路**：将$DNN$数据增强问题作为优化问题，使用遗传搜索($genetic\ algorithm,GA$算法)对每个训练数据的变体进行探索，以找到"$worst$"变体来增强，同时跳过某些增强($selective\ augmentation,SA$)的方式加速训练。其中，$GA$算法在$DNN$训练的每次迭代时探索少量变体并寻找最差变体，将其作为下次迭代的种子。$SA$通过在训练时对某些数据点的鲁棒性分析，跳过对其的增强，以减少$DNN$的训练时间

1. **最佳增强**$\mathbf{Optimal\ Augmentation}$

    自动化数据增强的最大挑战是寻找能让模型学习正确特征的最佳变体，因此使用遗传搜索(遗传搜索算法使用仿真进化和自然选择的方式高效探索空间)为每次迭代的每个数据点选择最佳变体，基于遗传算法的迭代性质，它可以被自然叠加在$DNN$的迭代训练上。使用遗传算法的三个主要步骤：染色体的表示、使用遗传算子生成种群、适应度函数的公式化

    * 染色体的表示$(representation\ of \ chromosomes)$

        在遗传算法$(GA)$中，染色体由一组基因组成，表示一种解决方案。在$SENSEI$中将对指定输入的一组操作(比如旋转$x$，再平移一个像素)作为染色体，即转换向量$\overset{\rightarrow}{\rho}=<\rho_1,\rho_2,...,\rho_k>$

    * 使用遗传算子生成种群$(generation\ of\ population\ using\ genetic\ operators)$

        在遗传算法$(GA)$中，种群表示代表解决方案子集的一组染色体。在$SENSEI$中，第一次迭代的种群随机生成，之后迭代中的种群通过变异和杂交，再经过排选择机制来生成

        * 变异：随机改变染色体的一个操作，即改变参数
        * 杂交：合并随机选择的两个染色体来生成一个新的染色体

        新生成的染色体确保会在设置的转化范围内，$SENSEI$只将染色体应用于原始图像以防止生成的数据不真实。生成新的种群后对其进行评估，然后将最佳的一组传递给下一次迭代

    * 适应度函数的公式化$(mathematical\ formulation\ of\ fitness\ function)$

        在遗传算法$(GA)$中，适应度函数衡量了当前方案(染色体)与最优方案的贴近程度。适应度函数很大程度上决定了算法的效率。$SENSEI$根据$DNN$的经验损失定义适应度函数，由于$DNN$的训练旨在最小化整个训练集的损失，因此应使用使$DNN$损失更大的变体。

        能根据测试输入度量$DNN$的指标都能作为适应度函数(比如$neuron\ coverage$和$surprise\ adequacy$)，但必须保证适应度函数的高效性

2. **选择性增强**$\mathbf{Selective\ Augmentation}$

    $SENSEI$-$SA$会跳过模型中鲁棒的数据点，选择性增强技术仅基于模型关于数据点的鲁棒性分析。对鲁棒的数据点使用以下两种指标对鲁棒性进行形式化：

    * 基于分类的鲁棒性$(classification$-$based\ robustness)$：仅当对所有的输入$x$和输入变异体$x'$都分类正确时，认为模型具有$point$-$wise$鲁棒性
    * 基于损失的鲁棒性$(loss$-$based\ robustness)$：仅当对所有的输入$x$和输入变异体$x'$都的预测损失值都小于设定的损失阈值时，认为模型具有$point$-$wise$鲁棒性

    $SENSEI$-$SA$首先确定模型是否关于种子输入$point$-$wise$鲁棒，然后仅对不鲁棒的种子进行增强

#### 实验设置

$\mathbf{RQ1}$：与当前最先进的方法相比，$SENSEI$对鲁棒性提升的有效性如何？

$\mathbf{RQ2}$：选择增强方法对减少训练时间的有效性如何？

$\mathbf{RQ3}$：超参数的值对$SENSEI$的有效性和效率的影响如何？

* **数据集和模型**

    选用的数据集及其描述如下表，其中$\#Train$表示训练集数量，$\#Test$表示测试集数量，$\#CL$表示类别数量，$\#MD$表示使用的$DNN$模型数量

![FuzzTesting-table1](..\Images\FuzzTesting-table1.png)

* **实际变体的生成**

    $SENSEI$致力于通过自然环境的变化进行数据增强以提高模型鲁棒性，使用两种方式操作图像：几何操作$(geometric\ operation)$和色彩操作$(color\ operation)$，以模拟相机移动和光线变化。并通过约束允许扰动变化的范围来保证变化后的图像仍然在视觉上与真实图像相似，主要使用的操作和约束如下：

    * $rotation(x,d)$：将图像$x$旋转$d$度，$[-30,30]$
    * $translation(x,d)$：水平或垂直将$x$移动$d$距离，$[-10\%,10\%]$
    * $shear(x,d)$：以$d$的裁剪因子水平裁剪图像$x$，$[-0.1,0.1]$
    * $zoom(x,d)$：将图像$x$放大/缩小系数$d$，$[0.9,1.1]$
    * $brightness(x,d)$：为图像$x$的每个像素添加或减去$d$，$[-32,32]$
    * $contrast(x,d)$：将图像$x$的每个像素的$RGB$值缩放$d$倍，$[0.8,1.2]$

    由于这些操作没有涉及图像外的像素的信息，因此其余像素值均设为0，即黑色

* **评价指标**

    当测试数据$x$的邻域内所有变换后的图像$x'$都是鲁棒的，则称$DNN$在$x$周围是鲁棒的。则模型对数据集的鲁棒准确性为：测试集中鲁棒的图像数量与测试集中图像总数的比例

#### 实验结果

* **针对**$\mathbf{RQ1}$：$\mathbf{SENSEI}$**的有效性**

    1. $SENSEI$在凸优化问题上的效果

        数据增强的效果取决于最大化凸优化问题的效率，即找到使模型损失最大的变体。将$SENSEI$与$Keras$内置的$Random\ augmentation$方法以及最新的针对自然变体的数据增强方法$W-10$作比较，并尽可能保证实验公平性。

        **结果**：$SENSEI$与其他两个方法的初始性能比较相近，但由于$SENSEI$的系统性，它的性能很快超过$W-10$和$Random$，$GTSRB$和$CIFAR-10$模型的对数损失图像如下：

        ![FuzzTesting-figure1](..\Images\FuzzTesting-figure1.png)

    2. $SENSEI$不同数量图像转换操作情况下与目前最新方法的比较

        当对输入数据的变换操作种类增加时，很难实现模型的鲁棒性，因此要探究$SENSEI$在这种情况下的性能。因此分别在有三种操作和六种操作时对鲁棒性准确性进行评估。

        **结果**：标准方法的模型准确率平均达到$91\%$以上，但鲁棒性准确率不足$5\%$，$Random\ augmentation$和$W-10$均对鲁棒性准确率有了提升，$SENSEI$分别比这两个方法平均提升了$8.2\%\sim18.7\%$和$1.7\%\sim6.1\%$。当数据变换操作从3个变成6个之后，所有方法的鲁棒性准确率都显著降低了，原因如下：

        * 六种操作使得变化后的图像与原图像的差异较大
        * 图像可能会产生更多的扰动，而任何一个扰动被分类错误，就会导致图像被分类错误

        然而在六中变换操作的情况下，$SENSEI$较之其他方法提升的鲁棒准确性更高了，分别比两个方法高$22.2\%$和$6.6\%$，也表明$SENSEI$更适合于庞大的搜索空间

        ![FuzzTesting-table2](..\Images\FuzzTesting-table2.png)

    3. $SENSEI$与基于对抗样本的重训练方法的比较

        $SENSEI$的效率取决于是否能在每次迭代中高效地选出数据点的最佳变体，而基于重训练的方法中，对抗样本一旦选定就不会在训练过程中改变了。所以控制$SENSEI$产生的变体数量与重训练生成的对抗样本数量相同以保证公平性，同时使用相同的变换操作生成对抗样本，并选择效果最佳的对抗样本用以重训练。

        **结果**：$SENSEI$比基于对抗样本的重训练方法提升了$10\%\sim27\%$的鲁棒性准确率

        ![FuzzTesting-table3](..\Images\FuzzTesting-table3.png)

    4. $SENSEI$是否能在提升鲁棒性泛化能力的同时保持模型准确率

        如果$SENSEI$能保证模型的预测能力，那么提升鲁棒性的泛化能力将会是绝对有益的

        **结果**：与不使用$SENSEI$的原始方法相比，$SENSEI$在提升鲁棒准确率的同时还提升了模型的预测能力(五个数据集中有四个数据集的预测准确率提升了)

        ![FuzzTesting-table4](..\Images\FuzzTesting-table4.png)

    5. $SENSEI$与最新的泛化方法$(mixup)$相比性能如何

        $mixup$是用于提升标准泛化能力$(standard\ generalization)$的一种数据增强方法

        **结果**：$mixup$与$SENSEI$都提升了标准泛化能力，$mixup$的效果略好；在鲁棒性泛化方面，$mixup$方法与没有进行数据增强的效果差不多，而$SENSEI$明显好于$mixup$

    **总结**：$SENSEI$比现有技术更有效地解决了内部最大化问题。与现有技术相比，它能够在保持模型准确率的同时，提升$11\%$的$DNN$模型鲁棒性准确率。在良性变异$(benign\ variation)$中，$SENSEI$比<u>基于对抗样本的重训练方法</u>和<u>以标准泛化能力为目标的数据增强方法</u>效果更好。

* **针对**$\mathbf{RQ2}$：**选择性数据增强的效果**

    从<u>训练时间</u>和<u>鲁棒准确率</u>两个方面比较$SENSEI$和$W$-$10$。标准方法每次迭代只有一次前向传播和后向传播，而$SENSEI$和$W$-$10$需要额外的前向传播来计算生成种群的适应度。

    **结果**：$SENSEI$-$SA$与$W$-$10$相比，提升了$3\%$的鲁棒性准确率，并且在选择性增强的方法下，$SENSEI$-$SA$平均减少了$25\%$的训练时间。但和$SENSEI$相比，$SENSEI$-$SA$降低了$0.5\%\sim1.5\%$的鲁棒性准确率。

* **针对**$\mathbf{RQ3}$：**超参数的敏感性**

    1. **种群数量**$(\mathbf{population\ size})$

        种群数量是影响遗传搜索的一个重要指标，因此对种群数量在3到30之间时进行研究。结果显示，种群数量越多，模型的鲁棒性准确率越高，但是训练时间越长，最终发现当种群数量在10到15之间时，$SENSEI$的性能最好。下图是将种群数量为3作为标准的比较图

        ![FuzzTesting-figure2](..\Images\FuzzTesting-figure2.png)

    2. **适应度函数**$(\mathbf{fitness\ function})$

        遗传搜索的性能很大程度上取决于适应度函数。将基于损失的适应度函数与基于覆盖率的损失函数作比较，二者对鲁棒性准确率的效果差不多，但基于覆盖率的适应度函数会消耗更多$(50\%)$时间。下图是鲁棒性准确率的对比

        ![FuzzTesting-table5](..\Images\FuzzTesting-table5.png)

    3. **选择指标**$(\mathbf{selection\ metrics})$

        $SENSEI$-$SA$在鲁棒性准确率以及训练时间的性能都是在鲁棒性指标性能的基础上的。基于损失的选择方法在所有模型上的性能都比基于分类的选择方法要好，因为基于损失的选择比基于分类的选择更保守$(conservation)$**（怎么理解？）**。下图是鲁棒性准确率的对比

        ![FuzzTesting-table6](..\Images\FuzzTesting-table6.png)

    4. **损失阈值**$(\mathbf{loss\ threshold})$

        在基于损失的选择方法中，损失阈值是影响性能的一个重要因素。结果显示，随行者损失阈值的减小，鲁棒性准确率和训练时间都在减小，有些数据集在鲁棒性准确率上对损失阈值很敏感，因此不同的数据集应有不同的损失阈值，$1e$-$3$的损失阈值是各个数据集相对平衡的一个损失阈值。下图中鲁棒性准确率以及(根据标准时间)标准化后的训练时间

        ![FuzzTesting-figure3](..\Images\FuzzTesting-figure3.png)





