## Prioritizing Test Inputs for Deep Neural Networks via Mutation Analysis

##### 提出一种通过智能变异的方式更早标记更能揭露bug的测试输入的测试输入优先级排序方法（PRIMA），算法基于“能够通过变异的测试输入杀死更多的变异模型并能产生不一样的预测结果的测试输入，更有可能揭露DNN的bug，因此需要有更高的优先级对其进行标记”的思想

#### 背景介绍

在深度学习中，DNN测试是保证DNN质量的重要方法。当前DNN测试的工作主要致力于提出不同的指标来评估测试输入的充分性，或是设计不同的方法来生成测试输入。然而对DNN的测试输入进行标记却会造成很大的代价，从而影响DNN测试的性能。标记数据代价较大的原因有三：测试集的规模很大；标记数据的主要方式是手动标记；标记数据时往往需要一些领域内的专业知识。

因此，对测试输入进行标记优先级排序就很重要，优先标记更有倾向于揭露模型bug的测试输入，以提升模型测试的效率。

当前已有的测试输入排序算法大都受限于性能问题或者特定的应用场景。比如基于覆盖的测试排序方法依据覆盖率对测试输入进行排序，性能往往低于基于置信度的测试排序方法。基于置信度的测试排序方法，如DeepGini，将测试输入在模型上不同分类的置信度作为排序依据，如果一个测试输入在模型上分类为不同类别的可能性更接近，它的置信度越低，因此需要有更高的标记优先级。然而DeepGini会受到特定应用场景的限制，例如只能应用于分类问题，并且只在图片分类问题上进行了评估；DeepGini基于“更能揭示bug的测试输入在不同的分类上有更接近的预测概率”的思路在很多场景下也不一定可靠。

#### 主要贡献

1. 通过变异分析提出了一种DNN的测试优先级排序方法。 设计了一系列模型和测试输入的变异规则，采用learning-to-rank算法结合变异结果，从而有效地进行了测试输入优先级划分。
2. 在36个项目中进行大规模研究，并从五个方面考虑了项目的多样性，证明了提出方法的有效性。
3. 将提出的方法应用于全球最有影响力的自动驾驶汽车公司之一，从而进一步证实了其实用性。

#### 方法介绍

PRIMA的思路基于两个部分：

1. 如果一个测试输入能够杀死很多的变异模型，说明这个测试输入对模型的测试更充分，更有倾向于揭露模型的bug。（如果测试输入使得模型在略微变异后和变异前的预测结果不同，则认为测试输入能杀死变异模型）
2. 如果测试输入略微变异后，与变异前的测试输入在DNN模型上的预测结果不同，说明DNN模型使用了测试输入的更多信息，从而测试输入对捕获DNN的bug更加敏感

PRIMA采用learning-to-rank方法（用于解决排序问题的有监督学习算法）构建排序模型，通过学习如何将变异结果用于不同的DNN模型，对测试输入进行优先级排序。

PRIMA方法主要分为三步：

1. 设计了一系列模型变异规则和测试输入变异规则，并获取了每个测试输入的变异结果
2. 从测试输入的变异结果中提取特征，以使用这些变异结果来确定测试输入的优先级
3. 使用learning-to-rank来构建排序模型，实现自动提取特征并确定测试输入的优先级

* **变异规则**

    变异规则包括**模型变异规则**和**测试输入变异规则**

    * 模型变异规则：神经元和权重是DNN的基本组成元素，因此基于现有工作设计了四种基于神经元（更细粒度）的变异规则

        1. 反转神经元的激活状态（Neuron Activation Inverse, NAI），在将神经元的激活状态传递给激活函数之前改变神经元的激活状态

        2. 阻断神经元的影响（Neuron Effect Block, NEB），将神经元传递给下一层的权重设置为0，以阻断神经元的影响

        3. 高斯模糊（Gauss Fuzzing, GF），通过高斯分布为神经元的权重添加噪声

        4. 打乱权重（Weights Shuffling, WS），打乱当前层神经元和上一层神经元之间的权重

        模型的变异规则只是轻微地改变模型，轻微的模型改变更能模拟真实的bug，并且能了解模型中的哪一部分是被测试输入充分测试过的；而模型的改变较大可能会导致模型失效，因此，PRIMA在每次仅随机采样$x\%$的神经元或权重进行变异

    * 测试输入变异规则：由于DNN的测试输入可能有不同的格式（如图片、序列数据、预定义特征），PRIMA针对每种数据的特征设计了变异规则，并且易于在其他类型的数据上扩展。尽管数据格式不同，但是思路都是对数据组成元素中的一小部分进行变异

        * 图片的变异规则
            1. 像素高斯模糊（Pixel Gauss Fuzzing, PGF），为图片选中的像素添加高斯分布的噪声
            2. 像素打乱（Pixel Shuffling, PS），打乱选中的像素
            3. 像素转白（Coloring Pixel White, CPW），将选中的像素变成白色
            4. 像素转黑（Coloring Pixel Black, CPB），将选中的像素变成黑色
            5. 像素颜色转换（Pixel Color Reverse, PCR），转换选中像素的颜色
        * 文本变异规则
            1. 文字打乱（Character Shuffling, CS），打乱选中的文字
            2. 文字替换（Character Replacement, CP），随机将选中的文字替换成文字集中的其他文字
            3. 文字重复（Character Repetition, CRE），重复选中的文字
        * 预定义特征变异规则
            1. 离散值替换（Discrete Value Replacement, DVR），将选中的特征值随机替换为离散值集中的其他值
            2. 连续值修改（Continuous Value Modification, CVM），将选中的特征值随机增加或减少$e\%$

        对于每一个测试输入，PRIMA生成m个变异模型以及n个变异测试输入，并获取他们的变异结果，也就是说，每个测试输入都有对应的变异模型和变异测试输入

* **特征提取**

    为了学习如何有效利用变异结果确定不同模型的测试输入的优先级，PRIMA使用learning-to-rank为每个DNN模型构建排名模型，因此类似其他的有监督学习模型，learning-to-rank需要用于学习的特征，因此需要从变异结果中提取特征。

    除了不同的预测结果之外，预测结果的不同程度也应该被考虑在“能够揭露bug的因素”之内。

    由于分类模型和回归模型的输出不同，需要分别对这两种模型进行特征提取，提取了两种不同的特征

    对于测试输入集$T=\{t_1,t_2,...,t_s\}$，模型$M$，$g$个分类$C=\{c_1,c_2,...,c_g\}$，通过变异规则$R$得到的变异模型$M^R=\{M_1^R,M_2^R,...,M_m^R\}$，通过变异规则$r$和测试输入$t_k$得到的变异测试输入集$t_k^r=\{t_{k1}^r,t_{k2}^r,...,t_{kn}^r\}$，$t_{ki}$通过变异规则$r$变异后在$M^R$上的预测概率为$P[t_{ki}^rM_j^R]=\{p[t_{ki}^rM_j^R]_1,p[t_{ki}^rM_j^R]_2,...,p[t_{ki}^rM_j^R]_g\}$，对应预测类别为$C[t_{ki}^rM_j^R]$，于是测试输入$t_k$在$M$上的特征表示如下：

    * $F_1$：测试输入在原始模型上的预测结果和经过$R$或$r$变异后的模型上的预测结果不同
        * $F_1^a$：使得$C[t_kM]$与$C[t_kM_j^R](或C[t_{ki}^rM])$不同的变异体的数量，即使得经过$R$或$r$变异后的预测结果与原始预测结果不同的变异体的数量
        * $F_1^b$：$C[t_kM_j^R](或C[t_{ki}^rM])$与$C[t_kM]$集合中不同元素的数量，即经过$R$或$r$变异后的预测结果集合与原始预测结果集合中不同元素的数量，反映了测试输入揭露bug的多样性
        * $F_1^c$：使得测试输入在模型上预测为“变异体预测分类与原始分类不同，且数量最大的分类”的变异体数量，在一定程度上反映了变异体对不同预测类别的分布
    * $F_2$：测试输入经过$R$或$r$变异后，在不同类别上的预测概率与原始测试输入的预测概率在一定程度上不同
        * $F_2^a$：$P[t_kM_j^R](或P[t_{ki}^rM])$与$P[t_kM]$之间的平均差异程度，即变异后对每个分类的预测概率的差异之和，计算公式为$\frac{\sum_{j=1}^mdist(P[t_kM_j^R],P[t_kM])}{m}$或$\frac{\sum_{i=1}^mdist(P[t_{ki}^rMP[t_kM])}{n}$，其中$dist$表示余弦距离
        * $F_2^b$：$P[t_kM_j^R](或P[t_{ki}^rM])$与$P[t_kM]$之间分布的差异程度，将$[0,1]$区间划分为十等份，并根据差异程度分别计算每个区间内的变异体数量
        * $F_2^c$：在其中一个分类下，原始预测概率与所有变异体的预测概率差异的平均值，原始测试输入在原始模型的预测分类中改变的概率更能体现揭露bug的能力

    由于回归模型输出的是数字而不是分类，因此无法提取类似$F_1$的特征，只能从预测结果的差异程度中提取每个测试输入的特征，包括：

    1. 原始测试输入在模型上的预测结果和突变体预测结果之间的平均差异，其中差异值是预测结果之间的绝对值
    2. 每个变异规则之间的分布差异，首先将回归结果归一化到$[0,1]$之间，然后将其平均分为十等份，并计算区间内变异体的数量

* **基于Learning-to-Rank的排序模型的构建**

    PRIMA使用提取的特征构建learning-to-rank算法的训练集，将每个测试输入作为一个实体，提取其对应的变异结果。对于分类问题，将其标记为0或1，表示当前的测试输入是否被模型错误预测了；对于回归问题，将其标记为预测值与真实值差异的绝对值，越大的值某种程度上表明其揭露bug能力越强，然后使用min-max normalization将其归一化为$[0,1]$之间

    之后使用learning-to-rank算法，以实现利用变异结果，以实现针对不同模型的最佳优先排序效果。并且使用XGBoost排名算法来构建基于learning-to-rank的排名模型，使用XGBoost的原因如下：

    1. 训练集中用于分类模型的标签都是0或1，可直接用于分类，而XGBoost排序算法擅长通过有效搜索最佳拆分来处理用于排序任务的分类标签
    2. XGBoost能够使用树集成模型从基本特征中有效地学习更复杂的特征
    3. 和其他learning-to-rank算法相比，XGBoost有更好的性能和效率
    4. 通过测量每个要素对排名模型的贡献，可以使排名结果易于解释

    基于排序模型，PRIMA会为测试集中的每个测试输入预测分数，然后根据其分数从高到低对所有测试输入进行优先级排序。在使用排序模型进行预测之前，需要从测试集中相应的变异结果中为每个测试输入提取特征。

#### 测试评估

对提出的方法PRIMA从五个方面进行评估：

* 不同领域的测试输入（图片、文字、预定义特征）
* 不同类型的测试输入（自然样本和对抗样本）
* DNN模型的不同任务（分类模型和回归模型）
* DNN模型的不同网络结构（CNN和DNN）
* 不同的训练场景（正常训练、带有脏数据的训练、转移学习）

结果显示，PRIMA比最新的方法在优先级效率上提升了$8.50\%\sim131.01\%$，并在4个实际模型中取得了很好的效果。





